{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignement_ML_Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradeep004/Udemy-Python-Programming/blob/main/Assignement_ML_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu-EAFoBMFNm"
      },
      "source": [
        "\n",
        "\n",
        "#Machine Learning Assignment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnLt7ISdzSf6"
      },
      "source": [
        "@Auther      : Pradeep Angadageri \n",
        "@Date_edited : 05/05/2021\n",
        "@Roll_Number : "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFq6MpmdM6de"
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2Yic8vhL4pO",
        "outputId": "7365c74e-cb42-4a72-ec2b-338744a93821"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsvo3E8BMqdD"
      },
      "source": [
        "#Loading of the \"Russia Investigation dataset\"\n",
        "data = pd.read_csv(\"/content/drive/My Drive/Masters/russia-investigation.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__kl7uhRdp8_"
      },
      "source": [
        "#Information about the columns and deciding which column will be helpful to predict the output.\n",
        "\n",
        "#Note - Columns marked as \"Important Feature\" will be considered for model building.\n",
        "\n",
        "#Columns with its description as per my understanding \n",
        "#1. investigation       : This tells what we are investigating, this can be considered as a id (Important Feature) \n",
        "#2. investigation-start : The date when investigation started (Not Important Feature)\n",
        "#3. investigation-end   : The date when investigation ended (Not Important Feature)\n",
        "#4. investigation-days  : difference between start date and end date of the investigation (Important Feature)\n",
        "#5. name                : Name of the person who is charged in the investigation (Not Important Feature) \n",
        "#6. indictment-days     : Length of the days between start date and charged date (Important Feature)\n",
        "#7. type                : Result of charge (Important Feature)\n",
        "#8. cp-date             : Date the person pled gulty or convicted if applicable (Not Importnat Feature)\n",
        "#9  cp-days             : Lenght of start date of the investigation to person pled gulty or convicted (Importnat Feature)\n",
        "#10 Overturned          : Conviction overturned or not (Importnat Feature)\n",
        "#11 American            : Charged person is america or not (Important Feature)\n",
        "#12 President           : WHo was the presedent during the investigation and person charged (Important Feature)\n",
        "#13 Pardoned            : Whether the person pardoned or not (Important Feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhPOKocYgfb7"
      },
      "source": [
        "##Task\n",
        "\n",
        "######Problem Statement : Using Regression and Classification Alogirthm , Predict whether the person is pardoned or not based on the input columns or data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHE7m1y6i7pg"
      },
      "source": [
        "#Steps that we will follow to complete this assignemnt \n",
        "#1)Remove Useless features from the data set \n",
        "#2)featurization of the columns \n",
        "#3)Applying Machine learning Algorithm \n",
        "#4)Measure the Models accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wKYcB5kN8QC"
      },
      "source": [
        "#Removing Useless Features from the dataset and taking only userfull features for preduction \n",
        "\n",
        "#Below are the reasons why features are important \n",
        "#1. investigation-start : Since the difference between start date and end date is given , this feature is not important\n",
        "#2. investigation-end   : Since the difference between start date and end date is given , this feature is not important\n",
        "#3. name                : With name we cannot make the model better, hence removing this feature.\n",
        "#4. cp-date             : Difference between start date and cp-date is given hence this feature can be removed.\n",
        "\n",
        "#Code to remove above four columns from the dataset\n",
        "data = data.drop(columns=[\"investigation-start\",\"investigation-end\",\"name\",\"cp-days\",\"cp-date\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3Ddc0yjo_ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "b0a53527-5c55-4b8b-b188-6ccedcda8576"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>investigation</th>\n",
              "      <th>investigation-days</th>\n",
              "      <th>indictment-days</th>\n",
              "      <th>type</th>\n",
              "      <th>overturned</th>\n",
              "      <th>pardoned</th>\n",
              "      <th>american</th>\n",
              "      <th>president</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>watergate</td>\n",
              "      <td>1492</td>\n",
              "      <td>-246.0</td>\n",
              "      <td>conviction</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Richard Nixon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>watergate</td>\n",
              "      <td>1492</td>\n",
              "      <td>-246.0</td>\n",
              "      <td>conviction</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Richard Nixon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>watergate</td>\n",
              "      <td>1492</td>\n",
              "      <td>292.0</td>\n",
              "      <td>conviction</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Richard Nixon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>watergate</td>\n",
              "      <td>1492</td>\n",
              "      <td>-246.0</td>\n",
              "      <td>guilty-plea</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>Richard Nixon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>watergate</td>\n",
              "      <td>1492</td>\n",
              "      <td>292.0</td>\n",
              "      <td>conviction</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Richard Nixon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>russia</td>\n",
              "      <td>659</td>\n",
              "      <td>422.0</td>\n",
              "      <td>indictment</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Donald Trump</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>russia</td>\n",
              "      <td>659</td>\n",
              "      <td>422.0</td>\n",
              "      <td>indictment</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Donald Trump</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>russia</td>\n",
              "      <td>659</td>\n",
              "      <td>422.0</td>\n",
              "      <td>indictment</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Donald Trump</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>russia</td>\n",
              "      <td>659</td>\n",
              "      <td>561.0</td>\n",
              "      <td>guilty-plea</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Donald Trump</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>russia</td>\n",
              "      <td>659</td>\n",
              "      <td>618.0</td>\n",
              "      <td>indictment</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Donald Trump</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>194 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    investigation  investigation-days  ...  american      president\n",
              "0       watergate                1492  ...      True  Richard Nixon\n",
              "1       watergate                1492  ...      True  Richard Nixon\n",
              "2       watergate                1492  ...      True  Richard Nixon\n",
              "3       watergate                1492  ...      True  Richard Nixon\n",
              "4       watergate                1492  ...      True  Richard Nixon\n",
              "..            ...                 ...  ...       ...            ...\n",
              "189        russia                 659  ...     False   Donald Trump\n",
              "190        russia                 659  ...     False   Donald Trump\n",
              "191        russia                 659  ...     False   Donald Trump\n",
              "192        russia                 659  ...      True   Donald Trump\n",
              "193        russia                 659  ...      True   Donald Trump\n",
              "\n",
              "[194 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWwtLSAYqDMV",
        "outputId": "8bcd1c81-312b-4fcc-a2ea-98df422552ad"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['investigation', 'investigation-days', 'indictment-days ', 'type',\n",
              "       'overturned', 'pardoned', 'american', 'president'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRyJk9NsaN0J"
      },
      "source": [
        "#Preprocessing \n",
        "data = data.rename(columns={'indictment-days ': 'indictment-days'})\n",
        "#Checked nan in all the columns and found 13 nan values in indictment-days , below code removes those rows \n",
        "data.dropna(subset = [\"indictment-days\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfB5Defxab7c",
        "outputId": "202d9a06-a22c-45b7-a433-51bc8593b1cf"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['investigation', 'investigation-days', 'indictment-days', 'type',\n",
              "       'overturned', 'pardoned', 'american', 'president'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSXsHGwRcrQL"
      },
      "source": [
        "#data['indictment-days'].isnull().values.any() # code to check nan values \n",
        "#data['indictment-days'].isnull().sum() # code to check count of nan values "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUjO9Mb0ouKj",
        "outputId": "e31b92cb-c0f5-4995-d921-f9aac6996ab5"
      },
      "source": [
        "#Seperate Input and output label and divide them into train and test data \n",
        "X = data[[\"investigation\",\"investigation-days\",\"indictment-days\",\"type\",\"overturned\",\"american\",\"president\"]]\n",
        "Y = data[\"pardoned\"]\n",
        "\n",
        "#Split data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33) # this is random splitting\n",
        "\n",
        "#Printing shapes after splitting the data \n",
        "print(\"*******************Printing shapes after splitting the dataset, for better understaing*******************\")\n",
        "print(\"Before splitting : \",data.shape)\n",
        "print(\"After splitting :\")\n",
        "print(\"X_train : \",X_train.shape)\n",
        "print(\"y_train : \",y_train.shape)\n",
        "print(\"X_test  : \",X_test.shape)\n",
        "print(\"y_test  : \",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*******************Printing shapes after splitting the dataset, for better understaing*******************\n",
            "Before splitting :  (181, 8)\n",
            "After splitting :\n",
            "X_train :  (121, 7)\n",
            "y_train :  (121,)\n",
            "X_test  :  (60, 7)\n",
            "y_test  :  (60,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIAcJr6asVxt",
        "outputId": "5934dbb2-e0a0-4562-895f-56255dde2356"
      },
      "source": [
        " # one-hot encoding of Investigation feature.\n",
        "inve_vectorizer = CountVectorizer()\n",
        "train_inve_feature_onehotCoding = inve_vectorizer.fit_transform(X_train[\"investigation\"])\n",
        "test_inve_feature_onehotCoding = inve_vectorizer.transform(X_test[\"investigation\"])\n",
        "\n",
        "\n",
        "#Converted investigation word feature to one hot encoded feature\n",
        "print(train_inve_feature_onehotCoding.shape)\n",
        "print(test_inve_feature_onehotCoding.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(121, 9)\n",
            "(60, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVL1qAzgUg-v"
      },
      "source": [
        "#Normal distribution of investigation-days feature\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "\n",
        "x = X_train[\"investigation-days\"]\n",
        "x = x.to_numpy()\n",
        "x = x.reshape(-1,1)\n",
        "\n",
        "y = X_test[\"investigation-days\"]\n",
        "y = y.to_numpy()\n",
        "y = y.reshape(-1,1)\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "min_max_scaler.fit(x)\n",
        "x_scaled = min_max_scaler.transform(x)\n",
        "y_scaled = min_max_scaler.transform(y)\n",
        "\n",
        "\n",
        "X_train[\"investigation-days\"] = x_scaled\n",
        "X_test[\"investigation-days\"] = y_scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flmyKDxUW8SN"
      },
      "source": [
        "#Normal distribution of indictment-days\t feature\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "\n",
        "x = X_train[\"indictment-days\"]\n",
        "x = x.to_numpy()\n",
        "x = x.reshape(-1,1)\n",
        "\n",
        "y = X_test[\"indictment-days\"]\n",
        "y = y.to_numpy()\n",
        "y = y.reshape(-1,1)\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "min_max_scaler.fit(x)\n",
        "x_scaled = min_max_scaler.transform(x)\n",
        "y_scaled = min_max_scaler.transform(y)\n",
        "\n",
        "\n",
        "X_train[\"indictment-days\"] = x_scaled\n",
        "X_test[\"indictment-days\"] = y_scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8veNHKqb8zU",
        "outputId": "b162eb85-8204-41e5-fc98-739d7dcd9551"
      },
      "source": [
        " # one-hot encoding of type feature.\n",
        "type_vectorizer = CountVectorizer()\n",
        "train_type_feature_onehotCoding = type_vectorizer.fit_transform(X_train[\"type\"])\n",
        "test_type_feature_onehotCoding = type_vectorizer.transform(X_test[\"type\"])\n",
        "\n",
        "\n",
        "#Converted investigation word feature to one hot encoded feature\n",
        "print(train_type_feature_onehotCoding.shape)\n",
        "print(test_type_feature_onehotCoding.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(121, 4)\n",
            "(60, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41p9PfyVflyA"
      },
      "source": [
        "#Mapping True/False to 0/1 for overtuned feature\n",
        "X_train[\"overturned\"] = X_train[\"overturned\"].astype(int)\n",
        "X_test[\"overturned\"] = X_test[\"overturned\"].astype(int)\n",
        "\n",
        "\n",
        "#Mapping True/False to 0/1 for pardoned feature\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "#Mapping True/False to 0/1 for american feature\n",
        "X_train[\"american\"] = X_train[\"american\"].astype(int)\n",
        "X_test[\"american\"] = X_test[\"american\"].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARNm3uoDhL3q",
        "outputId": "a0f58781-46b4-427f-c6b5-1db7864981d6"
      },
      "source": [
        " # one-hot encoding of type feature.\n",
        "pre_vectorizer = CountVectorizer()\n",
        "train_pre_feature_onehotCoding = pre_vectorizer.fit_transform(X_train[\"president\"])\n",
        "test_pre_feature_onehotCoding = pre_vectorizer.transform(X_test[\"president\"])\n",
        "\n",
        "\n",
        "#Converted investigation word feature to one hot encoded feature\n",
        "print(train_pre_feature_onehotCoding.shape)\n",
        "print(test_pre_feature_onehotCoding.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(121, 10)\n",
            "(60, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGw7G3wshlAC"
      },
      "source": [
        "train_onehotCoding = hstack((train_inve_feature_onehotCoding,train_type_feature_onehotCoding,train_pre_feature_onehotCoding))\n",
        "test_onehotCoding = hstack((test_inve_feature_onehotCoding,test_type_feature_onehotCoding,test_pre_feature_onehotCoding))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5xOkPLhmcXo"
      },
      "source": [
        "#training data\n",
        "\n",
        "#Working with investigation_days column\n",
        "investigation_days = np.array(X_train[\"investigation-days\"].values.tolist())\n",
        "investigation_days = investigation_days.reshape(investigation_days.shape[0],1)\n",
        "\n",
        "#Working with indictment_days column\n",
        "indictment_days = np.array(X_train[\"indictment-days\"].values.tolist())\n",
        "indictment_days = indictment_days.reshape(indictment_days.shape[0],1)\n",
        "\n",
        "#Working with overturned column\n",
        "overturned = np.array(X_train[\"overturned\"].values.tolist())\n",
        "overturned = overturned.reshape(overturned.shape[0],1)\n",
        "\n",
        "#Working with american column\n",
        "american = np.array(X_train[\"american\"].values.tolist())\n",
        "american = american.reshape(american.shape[0],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz16eVtDqml4"
      },
      "source": [
        "train_onehotCoding = hstack((train_onehotCoding,investigation_days,indictment_days,overturned,american)).tocsr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IugztcKJqdls"
      },
      "source": [
        "#testing data\n",
        "\n",
        "#Working with investigation_days column\n",
        "investigation_days = np.array(X_test[\"investigation-days\"].values.tolist())\n",
        "investigation_days = investigation_days.reshape(investigation_days.shape[0],1)\n",
        "\n",
        "#Working with indictment_days column\n",
        "indictment_days = np.array(X_test[\"indictment-days\"].values.tolist())\n",
        "indictment_days = indictment_days.reshape(indictment_days.shape[0],1)\n",
        "\n",
        "#Working with overturned column\n",
        "overturned = np.array(X_test[\"overturned\"].values.tolist())\n",
        "overturned = overturned.reshape(overturned.shape[0],1)\n",
        "\n",
        "#Working with american column\n",
        "american = np.array(X_test[\"american\"].values.tolist())\n",
        "american = american.reshape(american.shape[0],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcQRyrEAmIsd"
      },
      "source": [
        "test_onehotCoding = hstack((test_onehotCoding,investigation_days,indictment_days,overturned,american)).tocsr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD7yvL9ny8rY"
      },
      "source": [
        "###ML Algorithm : KNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSF7GCgxtsar"
      },
      "source": [
        "from sklearn.metrics.classification import accuracy_score, log_loss\n",
        "def predict_and_plot_confusion_matrix(train_x, train_y,test_x, test_y,clf):\n",
        " clf.fit(train_x, train_y)\n",
        " sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n",
        " sig_clf.fit(train_x, train_y)\n",
        " pred_y = sig_clf.predict(test_x)\n",
        " # for calculating log_loss we willl provide the array of probabilities belongs to each class\n",
        " print(\"Log loss :\",log_loss(test_y, sig_clf.predict_proba(test_x)))\n",
        " # calculating the number of data points that are misclassified\n",
        " print(\"Number of mis-classified points :\", np.count_nonzero((pred_y- test_y))/test_y.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8EdNUv9uelD",
        "outputId": "29980b86-3740-4194-e4d5-bad8f46fd502"
      },
      "source": [
        "#Applying classification algorithm that is KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "clf = KNeighborsClassifier(n_neighbors=10)\n",
        "predict_and_plot_confusion_matrix(train_onehotCoding, y_train, test_onehotCoding, y_test, clf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log loss : 0.4046278112685952\n",
            "Number of mis-classified points : 0.16666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGMew2U5y1iE"
      },
      "source": [
        "###ML Algorithm : Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJpMTv49voiY",
        "outputId": "3988f322-4e93-444b-d92a-cd295b1c4c54"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression().fit(train_onehotCoding, y_train)\n",
        "print(\"Linear Regression Score : \",reg.score(train_onehotCoding, y_train))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Regression Coeffient : \\n\",reg.coef_)\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Final output of Linear Regression\\n\",reg.predict(test_onehotCoding))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear Regression Score :  0.3633201199734575\n",
            "\n",
            "\n",
            "Regression Coeffient : \n",
            " [-5.64923936e+02 -9.74834828e+01  3.06073379e+02 -9.74834828e+01\n",
            " -8.63814791e+02  7.93221041e+02  3.55465135e+02  1.25695447e+02\n",
            " -5.42327937e+01  5.34657611e-03  1.00071549e-01 -1.05418152e-01\n",
            "  1.00071549e-01 -3.13083350e+02 -7.05937493e+01 -3.13083350e+02\n",
            "  3.55465135e+02 -7.05937493e+01  1.25695447e+02 -9.74834828e+01\n",
            "  1.25695447e+02 -9.74834828e+01  3.55465135e+02  2.25772625e+03\n",
            "  9.93862050e-02 -5.18132935e-02 -2.51254629e-01]\n",
            "\n",
            "\n",
            "Final output of Linear Regression\n",
            " [-1.49460853e-01 -7.82036665e-02  3.37760676e-01  1.85488145e-01\n",
            " -1.61949810e-01  9.02281756e-02 -3.49692691e-03 -5.14864047e-02\n",
            "  4.93146301e-01  1.00422920e-01  2.00956034e-01 -1.99349844e-01\n",
            "  3.48758947e-01  1.16592855e-01  1.53354200e-01 -1.02998376e-01\n",
            " -1.67351264e+03  3.88547437e-03  1.36229038e-01  1.96925050e-01\n",
            "  3.15713913e-01  4.65273970e-01  1.51546265e-01  3.88547437e-03\n",
            " -8.34457528e+02  1.39694247e-01 -5.14864047e-02  3.88547437e-03\n",
            " -3.47630058e-02  3.52500425e-01 -1.01642424e-01  3.19542729e-01\n",
            "  1.43109235e-01  1.16592855e-01 -1.02998376e-01  1.84001670e+00\n",
            " -1.37494653e+03  1.47126869e-01  6.51727332e-02 -3.49692691e-03\n",
            "  1.37886312e-01  2.44145592e-01  3.47001232e-01 -7.82036665e-02\n",
            "  1.55720140e-01 -3.36581567e-02 -5.61066830e-02  1.46373562e-01\n",
            "  1.98143690e-01  3.93278404e-01 -3.49692691e-03  3.27991862e-01\n",
            "  1.55720140e-01  2.12775978e-03  3.61188557e-01  1.57622936e-01\n",
            " -1.68930448e-01  2.72517728e-02  4.66680142e-01  1.16592855e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}